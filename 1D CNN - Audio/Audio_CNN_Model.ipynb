{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_CNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqN7fw0ZCjFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154eff5d-51dc-4263-8c57-4f2ed2ce0ba5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mASpLWa0PNqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05917ad8-9bcd-4c8a-f363-25619b938814"
      },
      "source": [
        "pip install boto"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 6.2MB/s \n",
            "\u001b[?25hInstalling collected packages: boto\n",
            "Successfully installed boto-2.49.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPOIAybuPF1C"
      },
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import boto\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8QbPyEhWh5t"
      },
      "source": [
        "The 1D CNN Model used to predict severity score of depressed patients and depression label. It is the part of multi fusion model.CNN used to classify spectrograms of normal participants (0) or depressed\n",
        "participants (1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeXqC2rPHuw6"
      },
      "source": [
        "\n",
        "prefix = '/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/Dataset/'\n",
        "df_train = pd.read_csv(prefix+'train_split_Depression_AVEC2017.csv')\n",
        "\n",
        "df_test = pd.read_csv(prefix+'dev_split_Depression_AVEC2017.csv')\n",
        "\n",
        "df_dev = pd.concat([df_train, df_test], axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKBXaFcdH1xh"
      },
      "source": [
        "K.set_image_data_format('channels_first')\n",
        "np.random.seed(15) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TXVZMDlPkpB"
      },
      "source": [
        "def preprocess(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Convert from float64 to float32 and normalize normalize to decibels\n",
        "    relative to full scale (dBFS) for the 4 sec clip.\n",
        "    \"\"\"\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n",
        "    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n",
        "    return X_train, X_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtklGO5lPnDz"
      },
      "source": [
        "def prep_train_test(X_train, y_train, X_test, y_test, nb_classes):\n",
        "    \"\"\"\n",
        "    Prep samples ands labels for Keras input by noramalzing and converting\n",
        "    labels to a categorical representation.\n",
        "    \"\"\"\n",
        "    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n",
        "                                                       X_test.shape[0]))\n",
        "    X_train, X_test = preprocess(X_train, X_test)\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TteIWnUOPp_f"
      },
      "source": [
        "def keras_img_prep(X_train, X_test, img_dep, img_rows, img_cols):\n",
        "    \"\"\"\n",
        "    Reshape feature matrices for Keras' expexcted input dimensions.\n",
        "    For 'th' (Theano) dim_order, the model expects dimensions:\n",
        "    (# channels, # images, # rows, # cols).\n",
        "    \"\"\"\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "        input_shape = (1, img_rows, img_cols)\n",
        "    else:\n",
        "        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "        input_shape = (img_rows, img_cols, 1)\n",
        "    return X_train, X_test, input_shape\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOrHStYYPulS"
      },
      "source": [
        "def cnn(X_train, y_train, X_test, y_test, batch_size,\n",
        "        nb_classes, epochs, input_shape):\n",
        "    \"\"\"\n",
        "    The Convolutional Neural Net architecture for classifying the audio clips\n",
        "    as normal (0) or depressed (1).\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='valid', strides=1,\n",
        "                     input_shape=input_shape, activation='relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(4, 3), strides=(1, 3)))\n",
        "\n",
        "    model.add(Conv2D(32, (1, 3), padding='valid', strides=1,\n",
        "              input_shape=input_shape, activation='relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 3)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        verbose=1, validation_data=(X_test, y_test))\n",
        "    score_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print('Train accuracy:', score_train[1])\n",
        "    score_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test accuracy:', score_test[1])\n",
        "\n",
        "    return model, history\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1RPGGzpPxLe"
      },
      "source": [
        "def model_performance(model, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    y_test_pred = model.predict_classes(X_test)\n",
        "    y_train_pred = model.predict_classes(X_train)\n",
        "    y_test_pred_proba = model.predict_proba(X_test)\n",
        "    y_train_pred_proba = model.predict_proba(X_train)\n",
        "    y_test_1d = y_test[:, 1]\n",
        "    conf_matrix = standard_confusion_matrix(y_test_1d, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_train_pred, y_test_pred, y_train_pred_proba, \\\n",
        "        y_test_pred_proba, conf_matrix\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvYMm1uAPz6c"
      },
      "source": [
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj4PPaOII7uj"
      },
      "source": [
        "\"\"\"\n",
        "Plots of test/train accuracy, loss, ROC curve.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def plot_accuracy(history):\n",
        "    \"\"\"\n",
        "    Plots train and test accuracy for each epoch.\n",
        "    \"\"\"\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/Experiments/cnn_accuracy1.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_loss(history):\n",
        "    \"\"\"\n",
        "    Plots train and test loss for each epoch.\n",
        "    \"\"\"\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/Experiments/cnn_loss1.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_roc_curve(y_test, y_score):\n",
        "    \"\"\"\n",
        "    Plots ROC curve for final trained model. Code taken from:\n",
        "    https://vkolachalama.blogspot.com/2016/05/keras-implementation-of-mlp-neural.html\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.05])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/Experiments/cnn_roc1.png')\n",
        "    plt.close()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rYNZ9CiJDKo",
        "outputId": "34accd66-6d30-4c13-f138-49906e4651e3"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    prefix=\"/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/randomly_sampled_data/\"\n",
        "    prefix1=\"/content/drive/MyDrive/Colab Notebooks/Depression Detection Code Workspace/Experiments/\"\n",
        "    print('Retrieving from drive...')\n",
        "    X_train = np.load(prefix+\"train_samples.npz\")\n",
        "    y_train = np.load(prefix+'train_labels.npz')\n",
        "    X_test = np.load(prefix+'test_samples.npz')\n",
        "    y_test = np.load(prefix+'test_labels.npz')\n",
        "\n",
        "    X_train, y_train, X_test, y_test = \\\n",
        "        X_train['arr_0'], y_train['arr_0'], X_test['arr_0'], y_test['arr_0']\n",
        "\n",
        "    # CNN parameters\n",
        "    batch_size = 64\n",
        "    nb_classes = 2\n",
        "    epochs = 25\n",
        "\n",
        "    print('Processing images for Keras...')\n",
        "    X_train, X_test, y_train, y_test = prep_train_test(X_train, y_train,\n",
        "                                                       X_test, y_test,\n",
        "                                                       nb_classes=nb_classes)\n",
        "    img_rows, img_cols, img_depth = X_train.shape[1], X_train.shape[2], 1\n",
        "    X_train, X_test, input_shape = keras_img_prep(X_train, X_test, img_depth,\n",
        "                                                  img_rows, img_cols)\n",
        "    print('Fitting model...')\n",
        "    model, history = cnn(X_train, y_train, X_test, y_test, batch_size,\n",
        "                         nb_classes, epochs, input_shape)\n",
        "    print('Evaluating model...')\n",
        "    y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba, \\\n",
        "        conf_matrix = model_performance(model, X_train, X_test, y_train, y_test)\n",
        "    print('Saving model locally...')\n",
        "    model_name = prefix1+'cnn_audio1.h5'\n",
        "    model.save(model_name)\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\".format(f1_score))\n",
        "    print('Saving plots...')\n",
        "    plot_loss(history)\n",
        "    plot_accuracy(history)\n",
        "    plot_roc_curve(y_test[:, 1], y_test_pred_proba[:, 1])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retrieving from drive...\n",
            "Processing images for Keras...\n",
            "Train on 4814 samples, validate on 1162\n",
            "Fitting model...\n",
            "Epoch 1/25\n",
            "76/76 [==============================] - 57s 203ms/step - loss: 0.6945 - accuracy: 0.5048 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6940 - accuracy: 0.5053 - val_loss: 0.6942 - val_accuracy: 0.4983\n",
            "Epoch 3/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6925 - accuracy: 0.5223 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6913 - accuracy: 0.5267 - val_loss: 0.6948 - val_accuracy: 0.4897\n",
            "Epoch 5/25\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 0.6909 - accuracy: 0.5368 - val_loss: 0.6953 - val_accuracy: 0.4776\n",
            "Epoch 6/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6916 - accuracy: 0.5267 - val_loss: 0.7008 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6902 - accuracy: 0.5314 - val_loss: 0.6960 - val_accuracy: 0.4880\n",
            "Epoch 8/25\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 0.6903 - accuracy: 0.5397 - val_loss: 0.6973 - val_accuracy: 0.4983\n",
            "Epoch 9/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6890 - accuracy: 0.5333 - val_loss: 0.6968 - val_accuracy: 0.4028\n",
            "Epoch 10/25\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 0.6888 - accuracy: 0.5521 - val_loss: 0.6984 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6882 - accuracy: 0.5423 - val_loss: 0.6997 - val_accuracy: 0.5009\n",
            "Epoch 12/25\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 0.6877 - accuracy: 0.5515 - val_loss: 0.6982 - val_accuracy: 0.3959\n",
            "Epoch 13/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6867 - accuracy: 0.5561 - val_loss: 0.6990 - val_accuracy: 0.4415\n",
            "Epoch 14/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6868 - accuracy: 0.5613 - val_loss: 0.7010 - val_accuracy: 0.4948\n",
            "Epoch 15/25\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 0.6876 - accuracy: 0.5673 - val_loss: 0.6993 - val_accuracy: 0.4475\n",
            "Epoch 16/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6858 - accuracy: 0.5606 - val_loss: 0.7003 - val_accuracy: 0.4441\n",
            "Epoch 17/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6858 - accuracy: 0.5647 - val_loss: 0.7024 - val_accuracy: 0.4914\n",
            "Epoch 18/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6856 - accuracy: 0.5543 - val_loss: 0.7018 - val_accuracy: 0.4535\n",
            "Epoch 19/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6817 - accuracy: 0.5781 - val_loss: 0.7013 - val_accuracy: 0.4544\n",
            "Epoch 20/25\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 0.6820 - accuracy: 0.5698 - val_loss: 0.7028 - val_accuracy: 0.4836\n",
            "Epoch 21/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6852 - accuracy: 0.5502 - val_loss: 0.7022 - val_accuracy: 0.4088\n",
            "Epoch 22/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6817 - accuracy: 0.5967 - val_loss: 0.7088 - val_accuracy: 0.5009\n",
            "Epoch 23/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6814 - accuracy: 0.5647 - val_loss: 0.7032 - val_accuracy: 0.4466\n",
            "Epoch 24/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6818 - accuracy: 0.5967 - val_loss: 0.7031 - val_accuracy: 0.4019\n",
            "Epoch 25/25\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6826 - accuracy: 0.5777 - val_loss: 0.7074 - val_accuracy: 0.4991\n",
            "Train accuracy: 0.5016618371009827\n",
            "Test accuracy: 0.4991394281387329\n",
            "Evaluating model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[  0   1]\n",
            " [581 580]]\n",
            "Saving model locally...\n",
            "Calculating additional test metrics...\n",
            "Accuracy: 0.4991394148020654\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1-Score: nan\n",
            "Saving plots...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J0q4f4ICQDv"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}